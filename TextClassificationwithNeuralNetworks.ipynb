{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSy-sfxOsclS"
   },
   "source": [
    "# Text Classification with Neural Networks\n",
    "\n",
    "In this project, we will build machine learning models to detect the sentiment of movie reviews using the IMDb movie reviews dataset. Specifically, implement classifiers based on Convolutional Neural Networks (CNN's) and Recurrent Neural Networks (RNN's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyCOvTRQ1nb-",
    "outputId": "d37a4de2-2ef2-49e9-b06f-bee81a2f261c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHbJ1-aDsWCG"
   },
   "source": [
    "# Step 1: Download the Data\n",
    "First the dataset is downloaded using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfX3bNby8FYL",
    "outputId": "36f17188-941e-4fed-9276-e4985da7a0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Train Examples: 20000\n",
      "Num. Test Examples: 5000\n",
      "\n",
      "SAMPLE DATA:\n",
      "Sample text: ['You', 'have', 'to', 'admire', 'Brad', 'Sykes', 'even', 'if', 'you', \"don't\", 'particularly', 'want', 'to', ',', 'a', 'man', 'who', 'churns', 'out', 'budget', 'horror', 'after', 'budget', 'horror', 'to', 'less', 'than', 'enthusiastic', 'receptions', '.', 'But', 'keeps', 'on', 'doing', 'it', 'all', 'the', 'same', '.', 'Even', 'the', 'half-hearted', 'praise', 'than', 'surrounds', 'his', 'Camp', 'Blood', 'films', 'is', 'given', 'grudgingly', 'and', \"I'm\", 'as', 'guilty', 'of', 'this', 'as', 'anyone', '.', 'Brad', 'normally', 'manages', 'to', 'throw', 'something', 'interesting', 'into', 'the', 'mix', ',', 'a', 'neat', 'idea', ',', 'a', 'kooky', 'character', ',', 'whatever', ',', 'but', 'without', 'the', 'funds', 'to', 'take', 'it', 'further', 'than', 'base', 'level', ',', 'he', 'relies', 'on', 'the', 'audience', 'to', 'cut', 'him', 'some', 'slack', 'and', 'appreciate', 'it', 'for', 'what', 'it', 'is', 'and', 'what', 'it', 'could', 'be', '.', 'Joe', 'Haggerty', 'gives', 'a', 'spirited', 'and', 'very', 'funny', 'performance', 'as', 'Ebenezer', 'Jackson', 'and', 'its', 'a', 'credit', 'to', 'Sykes', 'that', 'he', 'can', 'sense', 'that', 'this', 'oddball', 'turn', 'is', 'going', 'to', 'work', 'within', 'the', 'framework', 'of', 'the', 'film', '.', 'Coming', 'to', 'a', 'multiplex', 'near', 'you', ',', 'in', 'a', 'parallel', 'universe', ',', 'somewhere', '.']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['Lame', ',', 'cliched', 'superhero', 'action', 'movie', 'drivel', '.', 'I', 'had', 'high', 'hopes', 'for', 'this', 'movie', ',', 'and', 'the', 'genre', 'of', 'HK', 'buddy', 'cop', 'actioneers', 'is', 'one', 'that', 'i', \"don't\", 'despise', ',', 'but', 'very', 'rarely', 'do', 'i', 'see', 'a', 'storyline', 'as', 'trite', 'and', 'ludicrous', 'as', 'this', 'one', 'was', '.', 'This', 'would', 'have', 'been', 'forgivable', ',', 'as', 'it', 'always', 'is', 'in', 'these', 'kinds', 'of', 'movies', ',', 'when', 'the', 'action', 'compensates', ',', 'unfortunately', ',', 'it', 'did', 'not', '.', 'The', 'action', 'does', 'carry', 'the', 'trademark', 'surreality', 'and', 'over', 'the', 'top', 'nature', 'of', 'HK', 'action', ',', 'but', \"it's\", 'not', 'very', 'involving', ',', 'obscenely', 'gory', ',', 'and', 'in', 'fact', 'often', 'completely', 'incoherent', '(', 'perhaps', 'this', 'is', 'due', 'to', 're-editing', 'for', 'american', 'release', ',', 'it', 'does', 'show', 'signs', 'in', 'many', 'places', 'of', 'patchwork)', '.', 'I', 'was', 'very', 'disappointed', '.']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['I', 'read', 'some', 'comments', 'on', 'the', 'internet', 'about', 'this', 'film', 'like', '\"', '...harder', 'then', 'Hostel...\"', ',', '\"', 'the', 'camera', 'never', 'screens', 'of', 'when', \"it's\", 'getting', 'really', 'brutal...\"', '.', 'But', 'none', 'of', 'them', 'is', 'true', '.', 'The', 'camera', 'never', 'screens', 'of', ',', 'because', 'there', 'is', 'nothing', 'to', 'screen', 'of', '.', 'The', 'same', 'scene', 'is', 'repeated', 'hundred', 'and', 'hundred', 'times', 'again', '.', 'Women', 'lies', 'on', 'a', 'table', ',', 'killer', 'rapes', 'women', 'a', 'few', 'times', ',', 'killer', 'cuts', 'women', 'into', 'pieces', '(', 'you', 'never', 'see', 'this', 'during', 'the', 'whole', 'film!)', '.', 'Police', 'come', 'and', 'arrested', 'him', '.', 'Killer', 'fools', 'the', 'jury', '.', 'Film', 'over', '.', 'In', 'Germany', 'we', 'would', 'say', ':\"Viel', 'LÃ¤rm', 'um', 'Nichts\"', '.', 'All', 'in', 'all', ',', 'one', 'of', 'the', 'most', 'boring', 'films', 'I', 'ever', 'see', '.', 'Absolutely', 'non-recommendable', '.']\n",
      "Sample label: neg \n",
      "\n",
      "Sample text: ['Bromwell', 'High', 'is', 'nothing', 'short', 'of', 'brilliant', '.', 'Expertly', 'scripted', 'and', 'perfectly', 'delivered', ',', 'this', 'searing', 'parody', 'of', 'a', 'students', 'and', 'teachers', 'at', 'a', 'South', 'London', 'Public', 'School', 'leaves', 'you', 'literally', 'rolling', 'with', 'laughter', '.', \"It's\", 'vulgar', ',', 'provocative', ',', 'witty', 'and', 'sharp', '.', 'The', 'characters', 'are', 'a', 'superbly', 'caricatured', 'cross', 'section', 'of', 'British', 'society', '(', 'or', 'to', 'be', 'more', 'accurate', ',', 'of', 'any', 'society)', '.', 'Following', 'the', 'escapades', 'of', 'Keisha', ',', 'Latrina', 'and', 'Natella', ',', 'our', 'three', '\"', 'protagonists', '\"', 'for', 'want', 'of', 'a', 'better', 'term', ',', 'the', 'show', \"doesn't\", 'shy', 'away', 'from', 'parodying', 'every', 'imaginable', 'subject', '.', 'Political', 'correctness', 'flies', 'out', 'the', 'window', 'in', 'every', 'episode', '.', 'If', 'you', 'enjoy', 'shows', 'that', \"aren't\", 'afraid', 'to', 'poke', 'fun', 'of', 'every', 'taboo', 'subject', 'imaginable', ',', 'then', 'Bromwell', 'High', 'will', 'not', 'disappoint', '!']\n",
      "Sample label: pos \n",
      "\n",
      "Sample text: ['Any', 'one', 'who', 'has', 'seen', 'Mel', \"Gibson's\", 'The', 'Passion', 'of', 'the', 'Christ', 'and', 'was', 'bothered', 'by', 'the', 'gory', 'violence', 'would', 'want', 'to', 'see', 'this', 'film', 'instead', '.', 'Though', 'it', \"wasn't\", 'a', 'success', 'in', 'th', 'box', 'office', 'or', 'TV', 'ratings', ',', 'The', 'Fox', 'Movie', 'Channel', 'still', 'finds', 'a', 'real', 'good', 'motive', 'to', 'show', 'this', 'anually', '.', 'I', 'liked', 'the', 'way', 'that', 'they', 'trained', 'Chris', 'Sarandon', 'and', 'the', 'men', 'who', 'portrayed', 'his', 'disciples', 'to', 'sing', 'in', 'Hebrew.Though', 'Sarandon', \"didn't\", 'have', 'long', 'hair', 'like', 'any', 'other', 'Jesus', 'would', 'in', 'other', 'films', ',', 'his', 'looks', 'are', 'pretty', 'close', 'to', 'what', 'a', 'Jewish', 'man', 'would', 'appear', '.', 'What', 'surprised', 'me', 'or', 'startled', 'me', 'was', 'the', 'scene', 'where', 'Caiaphas', 'told', 'Jesus', 'about', 'Pilate', '\"', 'And', \"don't\", 'ever', 'forget', ',', 'that', 'you', 'are', 'a', 'Jew!', '\"', 'Though', 'that', 'may', 'have', 'not', 'been', 'a', 'racist', 'remark,Colin', 'Blakely', 'was', 'trying', 'to', 'make', 'Chris', 'Sarandon', 'look', 'like', 'garbage', 'in', 'the', 'eyes', 'of', 'the', 'prominent', 'men', 'of', 'those', 'days.Keith', \"Michell's\", 'portrayal', 'of', 'Pilate', 'was', 'hulking', ',', 'comparing', 'with', 'his', 'previous', 'performances', 'in', '\"', 'The', 'Story', 'of', 'Jacob', 'and', 'Joseph', '\"', 'and', '\"', 'The', 'Story', 'of', 'David\"', '.', 'But', 'if', 'you', 'compare', 'his', 'portrayal', 'of', 'Pilate', 'with', 'Telly', \"Savala's\", 'or', 'Hurd', 'Hatfield', ',', 'you', 'can', 'say', 'that', 'he', 'really', 'painted', 'well', 'the', 'impression', 'of', 'a', 'Roman', 'procurator', '.']\n",
      "Sample label: pos \n",
      "\n",
      "[('neg', ['I', 'would', 'put', 'this', 'at', 'the', 'top', 'of', 'my', 'list', 'of', 'films', 'in', 'the', 'category', 'of', 'unwatchable', 'trash', '!', 'There', 'are', 'films', 'that', 'are', 'bad', ',', 'but', 'the', 'worst', 'kind', 'are', 'the', 'ones', 'that', 'are', 'unwatchable', 'but', 'you', 'are', 'suppose', 'to', 'like', 'them', 'because', 'they', 'are', 'supposed', 'to', 'be', 'good', 'for', 'you', '!', 'The', 'sex', 'sequences', ',', 'so', 'shocking', 'in', 'its', 'day', ',', \"couldn't\", 'even', 'arouse', 'a', 'rabbit', '.', 'The', 'so', 'called', 'controversial', 'politics', 'is', 'strictly', 'high', 'school', 'sophomore', 'amateur', 'night', 'Marxism', '.', 'The', 'film', 'is', 'self-consciously', 'arty', 'in', 'the', 'worst', 'sense', 'of', 'the', 'term', '.', 'The', 'photography', 'is', 'in', 'a', 'harsh', 'grainy', 'black', 'and', 'white', '.', 'Some', 'scenes', 'are', 'out', 'of', 'focus', 'or', 'taken', 'from', 'the', 'wrong', 'angle', '.', 'Even', 'the', 'sound', 'is', 'bad', '!', 'And', 'some', 'people', 'call', 'this', 'art?<br', '/><br', '/>']), ('neg', ['Whoever', 'wrote', 'the', 'screenplay', 'for', 'this', 'movie', 'obviously', 'never', 'consulted', 'any', 'books', 'about', 'Lucille', 'Ball', ',', 'especially', 'her', 'autobiography', '.', \"I've\", 'never', 'seen', 'so', 'many', 'mistakes', 'in', 'a', 'biopic', ',', 'ranging', 'from', 'her', 'early', 'years', 'in', 'Celoron', 'and', 'Jamestown', 'to', 'her', 'later', 'years', 'with', 'Desi', '.', 'I', 'could', 'write', 'a', 'whole', 'list', 'of', 'factual', 'errors', ',', 'but', 'it', 'would', 'go', 'on', 'for', 'pages', '.', 'In', 'all', ',', 'I', 'believe', 'that', 'Lucille', 'Ball', 'is', 'one', 'of', 'those', 'inimitable', 'people', 'who', 'simply', 'cannot', 'be', 'portrayed', 'by', 'anyone', 'other', 'than', 'themselves', '.', 'If', 'I', 'were', 'Lucie', 'Arnaz', 'and', 'Desi', ',', 'Jr.', ',', 'I', 'would', 'be', 'irate', 'at', 'how', 'many', 'mistakes', 'were', 'made', 'in', 'this', 'film', '.', 'The', 'filmmakers', 'tried', 'hard', ',', 'but', 'the', 'movie', 'seems', 'awfully', 'sloppy', 'to', 'me', '.'])]\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import random\n",
    "\n",
    "def preprocess(review):\n",
    "    '''\n",
    "    Simple preprocessing function.\n",
    "    '''\n",
    "    res = []\n",
    "    for x in review.split(' '):\n",
    "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
    "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
    "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
    "        elif remove_beg: res += [x[0], x[1:]]\n",
    "        elif remove_end: res += [x[:-1], x[-1]]\n",
    "        else: res += [x]\n",
    "    return res\n",
    "\n",
    "if __name__=='__main__':\n",
    "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
    "    train_data = list(train_data)\n",
    "    train_data = [(x[0], preprocess(x[1])) for x in train_data]\n",
    "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n",
    "\n",
    "    print('Num. Train Examples:', len(train_data))\n",
    "    print('Num. Test Examples:', len(test_data))\n",
    "\n",
    "    print(\"\\nSAMPLE DATA:\")\n",
    "    for x in random.sample(train_data, 5):\n",
    "        print('Sample text:', x[1])\n",
    "        print('Sample label:', x[0], '\\n')\n",
    "    print(train_data[5:7])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kfg8RcyskyU"
   },
   "source": [
    "# Step 2: Create Dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvFX-iX5oq7T"
   },
   "source": [
    "## Define the Dataset Class\n",
    "\n",
    "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. The following functions are implemented: \n",
    "\n",
    "*   <b>` build_dictionary(self)`:</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training wordâs frequency should be `>= threshold` to be included in the dictionary.\n",
    "\n",
    "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
    "\n",
    "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
    "\n",
    "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
    "\n",
    "*   <b>` __getitem__(self, idx)`:</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1irMn3LX2YDB"
   },
   "outputs": [],
   "source": [
    "PAD = '<PAD>'\n",
    "END = '<END>'\n",
    "UNK = '<UNK>'\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import defaultdict\n",
    "\n",
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):        \n",
    "        self.examples = examples\n",
    "        assert split in {'train', 'val', 'test'}\n",
    "        self.split = split\n",
    "        self.threshold = threshold\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Dictionaries\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        if split == 'train':\n",
    "            self.build_dictionary()\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        \n",
    "        # Convert text to indices\n",
    "        self.textual_ids = []\n",
    "        self.convert_text()\n",
    "\n",
    "    \n",
    "    def build_dictionary(self): \n",
    "        '''\n",
    "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
    "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
    "        to control which words are assigned indices in the dictionaries.\n",
    "        Returns nothing.\n",
    "        '''\n",
    "        assert self.split == 'train'\n",
    "        word_theshold_count={}\n",
    "        # Don't change this\n",
    "        self.idx2word = {0:PAD, 1:END, 2: UNK}\n",
    "        self.word2idx = {PAD:0, END:1, UNK: 2}\n",
    "        indx=2\n",
    "        for x in self.examples:\n",
    "          for word in x[1]:\n",
    "            word=word.lower()\n",
    "            word_theshold_count[word]=word_theshold_count.get(word,0)+1\n",
    "            if word_theshold_count.get(word,0)>= self.threshold and self.word2idx.get(word,0)==0:\n",
    "              indx+=1\n",
    "              self.idx2word[indx]=word\n",
    "              self.word2idx[word]=indx\n",
    "        \n",
    "    \n",
    "    def convert_text(self):\n",
    "        '''\n",
    "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
    "        Store this in self.textual_ids; returns nothing.\n",
    "        '''\n",
    "        for x in self.examples:\n",
    "          review=[]\n",
    "          for word in x[1]:\n",
    "            word=word.lower()\n",
    "            indx=self.word2idx.get(word,\"not present\")\n",
    "            if  indx!=\"not present\":\n",
    "              review.append(indx)\n",
    "            else:\n",
    "                review.append(self.word2idx.get(UNK))\n",
    "          review.append(self.word2idx.get(END))\n",
    "          self.textual_ids.append(review)   \n",
    "      \n",
    "\n",
    "    def get_text(self, idx):\n",
    "        '''\n",
    "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
    "        You may need to pad as necessary (see above).\n",
    "        '''\n",
    "        review=self.textual_ids[idx]\n",
    "        if len(self.textual_ids[idx])<self.max_len:\n",
    "          for i in range(len(self.textual_ids[idx]),self.max_len):\n",
    "            review.append(self.word2idx.get(PAD))\n",
    "        else:\n",
    "          review=review[:self.max_len]    \n",
    "        return torch.LongTensor(review)\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        '''\n",
    "        This function should return the value 1 if the label for idx in the dataset is 'positive', \n",
    "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
    "        '''\n",
    "        if self.examples[idx][0]==\"neg\":\n",
    "          return torch.squeeze(torch.LongTensor([0]))\n",
    "\n",
    "        return torch.squeeze(torch.LongTensor([1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the number of reviews (int value) in the dataset\n",
    "        '''\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Return the review, and label of the review specified by idx.\n",
    "        '''\n",
    "        return self.get_text(idx),self.get_label(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvHIZt8Z-RzK",
    "outputId": "586de572-6ca0-42f4-fde7-e58f3181f987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset:\n",
      "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
      "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
      "\n",
      "--- TEST: idx2word and word2idx dictionaries ---\n",
      "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
      "\n",
      "--- TEST: len(dataset) ---\n",
      "\tPASSED\n",
      "\n",
      "--- TEST: __getitem__(self, idx) ---\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
      "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
     ]
    }
   ],
   "source": [
    "def sanityCheckDataSet():\n",
    "    #\tRead in the sample corpus\n",
    "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
    "               ('neg', 'Life is bad when you got not a lot')]\n",
    "    data = [(x[0], preprocess(x[1])) for x in reviews]\n",
    "    print(\"Sample dataset:\")\n",
    "    for x in data: print(x)\n",
    "\n",
    "    thresholds = [1,2,3]\n",
    "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
    "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
    "    for i in range(len(thresholds)):\n",
    "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
    "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
    "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
    "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
    "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
    "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
    "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
    "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
    "        if has_passed: # Check that word2idx and idx2word are consistent\n",
    "            widx = sorted(list(dataset.word2idx.items())) \n",
    "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
    "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
    "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
    "    \n",
    "    print('\\n--- TEST: len(dataset) ---')\n",
    "    has_passed = len(dataset) == 2\n",
    "    if has_passed: print('\\tPASSED')\n",
    "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
    "\n",
    "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
    "    max_lens = [3,8,15]\n",
    "    idxes = [0,1]\n",
    "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
    "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
    "        returned = dataset.__getitem__(combo['idx'])\n",
    "\n",
    "        has_passed, message = True, ''\n",
    "        if has_passed and len(returned) != 2:\n",
    "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 things. Got ' + str(len(returned)) +' things instead.'\n",
    "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
    "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
    "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
    "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
    "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
    "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
    "        if has_passed and (returned[1] != correct[i][1]):\n",
    "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
    "        if has_passed:\n",
    "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[PAD])[0]\n",
    "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
    "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
    "\n",
    "        status = 'PASSED' if has_passed else 'FAILED'\n",
    "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sanityCheckDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR4VQbQCNZH6"
   },
   "source": [
    "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSxpGXj6ml9N",
    "outputId": "49467896-bfcf-4019-9789-eb284284f5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 19002 \n",
      "\n",
      "Example text:\n",
      "['Ronald', 'Colman', 'plays', 'a', 'famous', 'Broadway', 'actor', 'who', 'has', 'begun', 'to', 'lose', 'his', 'mind', 'and', 'sense', 'of', 'identity', '.', 'After', 'years', 'of', 'playing', 'a', 'wide', 'range', 'of', 'parts', ',', 'he', \"can't\", 'remember', 'who', 'he', 'exactly', 'is--who', 'are', 'his', 'roles', 'and', 'who', 'is', 'the', 'self', '.', 'And', ',', 'much', 'more', 'serious', ',', 'he', 'begins', 'to', 'see', 'and', 'hear', 'his', 'play', 'even', 'in', 'regular', 'everyday', 'life', '.', 'So', ',', 'since', \"he's\", 'currently', 'playing', 'in', '\"', 'Othello\"', ',', 'he', 'begins', 'to', 'act', 'jealous', 'and', 'suspicious--just', 'like', 'the', 'title', 'character', '.', 'Ultimately', ',', 'it', 'leads', 'him', 'to', 'the', 'depths', 'of', 'insanity', 'and', 'murder.<br', '/><br', '/>I', 'saw', 'this', 'film', 'years', 'ago', 'and', 'liked', 'it', '.', 'I', 'just', 'saw', 'it', 'again', 'and', 'loved', 'it', '.', 'Now', 'perhaps', 'some', 'of', 'my', 'enthusiasm', 'is', 'because', 'I', 'have', 'always', 'liked', 'Ronald', 'Colman', 'and', 'this', 'is', 'a', 'great', 'triumph', 'for', 'him--and', 'for', 'which', 'he', 'earned', 'the', 'Best', 'Actor', 'Oscar', '.', 'And', ',', 'looking', 'at', 'the', 'competition', 'that', 'year', '(', 'Gregory', 'Peck', 'for', \"GENTLEMAN'S\", 'AGREEMENT', ',', 'John', 'Garfield', 'for', 'BODY', 'AND', 'SOUL', ',', 'William', 'Powell', 'for', 'LIFE', 'WITH', 'FATHER', 'and', 'Michael', 'Redgrave', 'for', 'MOURNING', 'BECOMES', 'ELECTRA)', ',', 'I', 'think', 'Colman', 'was', 'a', 'very', 'good', 'choice', ',', 'as', 'he', 'stretched', 'from', 'his', 'usual', 'comfort', 'zone', 'and', 'did', 'a', 'much', 'more', 'demanding', 'role.<br', '/><br', '/>Now', 'I', 'noticed', 'that', 'one', 'reviewer', 'hated', 'this', 'film', 'because', 'they', 'hated', 'Shakespeare--and', 'this', 'took', 'up', 'about', 'half', 'their', 'review', 'talking', 'about', 'their', 'dislike', 'for', 'him', '.', 'However', ',', 'this', 'film', \"isn't\", 'really', 'about', 'Shakespeare', ',', 'and', 'it', \"doesn't\", 'matter', 'at', 'all', 'if', 'you', 'dislike', 'Shakespeare', '.', 'I', 'am', 'no', 'huge', 'fan', 'of', 'Shakespeare', ',', 'but', 'marveled', 'at', 'the', 'small', 'portions', 'of', 'the', 'play', 'that', 'Colman', 're-enacted--though', ',', 'as', 'I', 'said', ',', 'this', 'is', 'NOT', 'a', 'really', 'movie', 'about', 'Shakespeare', '.', 'Instead', ',', \"it's\", 'a', 'wonderful', 'portrait', 'of', 'an', 'actor', 'losing', 'his', 'mind', 'and', 'mixing', 'his', 'stage', 'role', 'with', 'reality', '.', 'It', 'could', 'have', 'been', 'ANY', 'play', ',', 'though', '\"', 'Othello', '\"', 'was', 'an', 'excellent', 'choice', 'because', 'of', 'the', 'murder', 'scene--which', 'gets', 'acted', 'out', 'for', 'real', 'later', 'in', 'the', 'film.<br', '/><br', '/>Overall', ',', 'a', 'very', 'clever', 'film', 'due', 'to', 'a', 'lovely', 'script--with', 'some', 'overtones', 'of', 'Film', 'Noir', '.', 'Fortunately', ',', 'the', 'acting', 'was', 'terrific', 'also', ',', 'as', 'Colman', 'had', 'excellent', 'support', 'from', 'Signe', 'Hasso', ',', 'Shelly', 'Winters', 'and', 'Edmond', \"O'Brien\", '(', 'who', 'was', 'particularly', 'good--he', 'played', 'his', 'part', 'just', 'right)', '.', 'And', ',', 'considering', 'the', 'great', 'George', 'Cukor', 'was', 'directing', ',', \"it's\", 'no', 'wonder', \"it's\", 'a', 'wonderful', 'film', 'from', 'start', 'to', 'finish', '.']\n",
      "tensor([ 8378, 16722,   773,    10,  1106,  2377,   417,    36,    38, 10098,\n",
      "            8,  2260,    41,   411,     7,   193,     9,  2118,     5,   153,\n",
      "           59,     9,   389,    10,  2676,  4066,     9,   495,     3,   110,\n",
      "          215,   451,    36,   110,   659,     2,    21,    41,   789,     7,\n",
      "           36,    15,     6,  1238,     5,     7,     3,    95,    74,   522,\n",
      "            3,   110,  1578,     8,    37,     7,  1093,    41,   446,    64,\n",
      "            4,  2238,  5111,   132,     5,    33,     3,   455,   370,  4327,\n",
      "          389,     4,    20,     2,     3,   110,  1578,     8,   557,  4965,\n",
      "            7,     2,    55,     6,   346,   191,     5,  1404,     3,    11,\n",
      "          981,   154,     8,     6,  4335,     9,  9145,     7, 16721,    17,\n",
      "          169,   300,    12,    13,    59,   715,     7,  1269,    11,     5,\n",
      "           14,    61,   300,    11,   246,     7,  1444,    11,     5,   343,\n",
      "          439,    42,     9,    80,  7265,    15,    63,    14,    54,   353,\n",
      "         1269,  8378, 16722,     7,    12,    15,    10,   139,  6543,    19,\n",
      "            2,    19,    84,   110,  5924,     6,   258,   417,  1246,     5])\n",
      "\n",
      "Example label:\n",
      "pos\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
    "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
    "\n",
    "    randidx = random.randint(0, len(train_dataset)-1)\n",
    "    text, label = train_dataset[randidx]\n",
    "    print('Example text:')\n",
    "    print(train_data[randidx][1])\n",
    "    print(text)\n",
    "    print('\\nExample label:')\n",
    "    print(train_data[randidx][0])\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_4FFhulaAod"
   },
   "source": [
    "# Step 3: Train a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcSKydlClwOC"
   },
   "source": [
    "## Define the CNN Model \n",
    "Here we will define convolutional neural network for text classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ztuy2hUaAof"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        self.embeddding= nn.Embedding(vocab_size, embed_size, pad_idx, max_norm=None, \n",
    "                           norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None)\n",
    "\n",
    "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your \n",
    "        #   different filter_heights.\n",
    "        in_channels=1\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels, out_channels, (filter_ht, embed_size)) for filter_ht in filter_heights])\n",
    "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained \n",
    "        #   for each convolution layer)\n",
    "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
    "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n",
    "        #   in one direction\n",
    "\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units \n",
    "        #   and takes as input the concatenated output for all cnn layers (out_channels * num_of_cnn_layers units)\n",
    "        self.fc1 = nn.Linear(len(filter_heights) * out_channels, num_classes)\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, max_len]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
    "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        word_embeddings=self.embeddding(texts)\n",
    "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
    "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
    "        word_embeddings = word_embeddings.unsqueeze(1)\n",
    "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
    "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
    "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
    "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
    "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
    "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
    "        #\n",
    "        output = [F.relu(conv(word_embeddings)).squeeze(3) for conv in self.convs]\n",
    "        # Let's understand what you just did:\n",
    "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
    "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
    "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
    "        #   Then you applied a non-linearity and took the max value for all channels\n",
    "        #     You are essentially trying to find important n-grams from the entire text\n",
    "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in output]\n",
    "        # Apply dropout\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        logit = self.fc1(x)\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy9oF6qUUHvV",
    "outputId": "8a25f039-5a75-4ffc-b67a-17e8ee29c9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
      "\n",
      "--- TEST: Output shape of forward(...) ---\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([20, 150])\tExpected Output Shape: torch.Size([20, 2])\tYour Output Shape: torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, data_loader):\n",
    "    print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
    "    \n",
    "    if init_or_forward == \"forward\":\n",
    "        # Reading the first batch of data for testing\n",
    "        for texts_, labels_ in data_loader:\n",
    "            texts_batch, labels_batch = texts_, labels_\n",
    "            break\n",
    "\n",
    "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):       \n",
    "        if init_or_forward == \"forward\":\n",
    "            batch_size = test_params['batch_size']\n",
    "            texts = texts_batch[:batch_size]\n",
    "\n",
    "        # Construct the student model\n",
    "        tps = {k:v for k, v in test_params.items() if k != 'batch_size'}\n",
    "        stu_nn = NN(**tps)\n",
    "\n",
    "        if init_or_forward == \"forward\":\n",
    "            with torch.no_grad(): \n",
    "                stu_out = stu_nn(texts)\n",
    "            ref_out_shape = expected_output\n",
    "\n",
    "            has_passed = torch.is_tensor(stu_out)\n",
    "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
    "            else: \n",
    "                has_passed = stu_out.shape == ref_out_shape\n",
    "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
    "            \n",
    "\n",
    "            status = 'PASSED' if has_passed else 'FAILED'\n",
    "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(texts.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
    "            print(message)\n",
    "        else:\n",
    "            stu_num_params = count_parameters(stu_nn)\n",
    "            ref_num_params = expected_output\n",
    "            comparison_result = (stu_num_params == ref_num_params)\n",
    "\n",
    "            status = 'PASSED' if comparison_result else 'FAILED'\n",
    "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
    "            print(message)\n",
    "\n",
    "        del stu_nn\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
    "    expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 20}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2]), torch.Size([1, 2]), torch.Size([20, 2])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, CNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FupiBIfasCu_"
   },
   "source": [
    "## Train CNN Model\n",
    "\n",
    "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2QYl334n9ON"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 \n",
    "    MAX_LEN = 200 \n",
    "    BATCH_SIZE = 32 \n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LD-Jj2rUFOzr"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, num_epochs, data_loader, optimizer, criterion):\n",
    "    print('Training Model...')\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for texts, labels in data_loader:\n",
    "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
    "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(texts)\n",
    "            acc = accuracy(output, labels)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
    "    print('Model Trained!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVP2scuyhG5f"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    output: Tensor [batch_size, n_classes]\n",
    "    labels: LongTensor [batch_size]\n",
    "    \"\"\"\n",
    "    preds = output.argmax(dim=1) # find predicted class\n",
    "    correct = (preds == labels).sum().float() # convert into float for division \n",
    "    acc = correct / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5UtdjGDuBty",
    "outputId": "04df3cfa-a406-4399-e9f3-d92eee7bdf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,879,746 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                out_channels = 64, \n",
    "                filter_heights = [2, 3, 4], \n",
    "                stride = 1, \n",
    "                dropout = 0.5, \n",
    "                num_classes = 2, \n",
    "                pad_idx = train_dataset.word2idx[PAD]) \n",
    "\n",
    "    # Put the model on the device (cuda or cpu)\n",
    "    cnn_model = cnn_model.to(DEVICE)\n",
    "    \n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoeyQL4PoNoH"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 5e-4 #learning rates\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopLfAJ9wOHN"
   },
   "source": [
    "Finally, we can train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "b0760a205da8490fa94b0f5597c478e0",
      "89a8777537bc48359942a911ac80c2a6",
      "ac22a2eba6b741d5acd0d04bd897050e",
      "003de8d84d4a4eb0a9d697999b4f2be0",
      "8446114f8cea415ebd55567ec17177cd",
      "4f99333efd0e4807a8993d7994656ec7",
      "eefa20ac58e84d6d9d37f750bf2ee685",
      "59edd186b3d6454682a61124014807fa",
      "6276074cc05a4d88b4d94cfa19622aa5",
      "5c795e3ecaeb4c9c80bf5489e206bc24",
      "f616197f58614627a5ce157ccce3e350"
     ]
    },
    "id": "lPOs1FifoNoN",
    "outputId": "76b4f582-adda-494d-99e3-e4d4cefdf2b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0760a205da8490fa94b0f5597c478e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.6923\t Train Accuracy: 60.13%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.5603\t Train Accuracy: 71.09%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.4970\t Train Accuracy: 75.81%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.4513\t Train Accuracy: 78.62%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.4193\t Train Accuracy: 80.74%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.3761\t Train Accuracy: 83.27%\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.3420\t Train Accuracy: 85.22%\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.3037\t Train Accuracy: 87.21%\n",
      "[TRAIN]\t Epoch:  9\t Loss: 0.2575\t Train Accuracy: 89.10%\n",
      "[TRAIN]\t Epoch: 10\t Loss: 0.2246\t Train Accuracy: 90.99%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    N_EPOCHS = 10 \n",
    "    \n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-OJbZ72t6Yq"
   },
   "source": [
    "## Evaluate CNN Model\n",
    "\n",
    "Now that we have trained a model for text classification, it is time to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTiiYDZIF--7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
    "    print('Evaluating performance on the test dataset...')\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    all_predictions = []\n",
    "    print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
    "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
    "    total = 0\n",
    "    for texts, labels in iterator:\n",
    "        bs = texts.shape[0]\n",
    "        total += bs\n",
    "        texts = texts.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        output = model(texts)\n",
    "        acc = accuracy(output, labels) * len(labels)\n",
    "        pred = output.argmax(dim=1)\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "        loss = criterion(output, labels) * len(labels)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        if random.random() < 0.0015 and bs == 1:\n",
    "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[PAD], data_loader.dataset.word2idx[END]}]))\n",
    "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
    "\n",
    "    full_acc = 100*epoch_acc/total\n",
    "    full_loss = epoch_loss/total\n",
    "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
    "    predictions = torch.cat(all_predictions)\n",
    "    return predictions, full_acc, full_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503,
     "referenced_widgets": [
      "a20f07cffd3e4ff7b183de9c5371a403",
      "59d71e2aaa344b889780872f4f908589",
      "5e826625eba442f2bdc97823a848b148",
      "fb2540bd84434509b961e3654478c790",
      "5a05d4e03e6d473ba0c258c0183b3e9a",
      "66f85b00d7c04448b8819b49f7af35f1",
      "dba97039d7184983a5a84560d34d2951",
      "448ea785839146f6b39bfc2a853dbee4",
      "95364d7916c343668e22d462499e0428",
      "8110a9a5dc4c4dd483841f93911244f6",
      "a5488b705e064cda8afd45255ecfbcbe"
     ]
    },
    "id": "Z718w8e0oNoS",
    "outputId": "249078b4-4847-4950-a589-67470fe24e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20f07cffd3e4ff7b183de9c5371a403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: the omega code was a model of <UNK> inconsistency . there was a bit ( but precious little ) of good acting , primarily by the two <UNK> and <UNK> , who only appeared once and had no lines . otherwise the acting was decidedly bad . the plot line was rather weak , and only partially based on already questionable biblical interpretation . certainly not one of the year's best .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: this sure is one comedy i'm not likely to forget for a while.<br /><br <UNK> normally bother to comment on this movie : it's so minor that no one would watch it anyway , but as it happens , it's kind of popular in <UNK> sharing networks such as <UNK> , and so this <UNK> production needs to be exposed for what it is.<br /><br />so what is it then ? well , of course it's not really a comedy ; instead , it's intended as a horror flick -- \" intended \" very much being the key word here . the script is a totally incoherent and unbalanced mess , the special effects are only special in that they're especially pathetic , and as for the acting , well , let's just say that if this had been my <UNK> play at primary school , my teachers would have burst out crying at our talent.<br /><br />of course i realise that this is a very low budget film and that in those cases one should lower one's expectations , certainly as far as things like special effects are concerned . also , even though i'm a big fan of\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: i personally liked this movie and am alarmed at the <UNK> some people have given it . it is a movie based on a comic book and it is animated , now if you don't like comic books or animation then of course you won't like this movie so why did you watch and bother to rate it is beyond me . though , if you are a fan of interesting , strong characters and <UNK> ) women kicking butt and saving the <UNK> ) you will love this movie . i thought the story really pulled me in and it was a very cool movie . quite <UNK> or more like some of the american movies following this new trend of adult animation . like titan <UNK> . <UNK> the live action version of punisher . in the end i highly recommend this movie the comic buff and super hero fan or anyone with an open enough mind looking for a fun movie .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: \" bruce almighty \" looks and sounds incredibly stupid , especially from the trailers . nevertheless , i found in it a deeper message that actually made me like this film more . bruce ( jim carrey ) is angry at god and is given divine powers by him to be god for a week to see if he can do a better job . morgan freeman plays a man symbolized here as god , and though it isn't his usual type of film or one of his best roles , he does excellent with what he is given to work with . although crude at times , the film does have quite a few laughs , from bruce parting his soup in half like the red sea and the customers ' reactions to him , as well as freeman's seemingly laid-back and wisecracking image of god . it is overly exaggerated at times , and there is some crude humor , but overall it manages to be somewhat funny . there is a decent supporting cast , such as jennifer aniston , lisa ann walter , and steve carrell , which always helps . the end of the film\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: yet another example of what british cinema can achieve : a simple story , told and acted well . brenda blethyn gives a layered and warming performance as the recently widowed and financially <UNK> grace , ably assisted by a solid supporting cast . the \" quirky small town \" card gets played to the hilt , similar to many tv series and films that have come from the british isles in recent years ( <UNK> , <UNK> macbeth and others come to mind) . like the <UNK> , this film makes use of some <UNK> beautiful rural scenery , in this case the wet and wild <UNK> <UNK> /><br />some viewers might find wholesale acceptance of cannabis use a bit challenging , others might find the ending just a little too cute and safe . but it's an enjoyable <UNK> , to be sure .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: this is definitely one of the best kung fu movies ever , and may be one of the best movies <UNK> . it's got a great plot that functions like a puzzle , with lots of intrigue and suspense . this film is full of cat and mouse games and <UNK> , with people hiding their identities and their natures . the characters in this film live and breath much more than your average kung fu movie characters . they are all interesting and compelling and the movie does a good job at giving them scenes to show their <UNK> and <UNK> /><br />the fight scenes play out like little stories and many of them are very original and exciting . it has cool training sequences and martial arts skills that are so awesome they enter the realm of fantasy . there are 5 members of the poison clan each one with his own style that <UNK> the special skill of a venomous animal . the styles of each of these characters are fun to watch and you can see the techniques they use in training applied during the film.. . when this happens , the director uses quick cutting\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: well.. . easily my favourite tv series ever . call me a walking mail clichÃ© but include violence , mafia , sex , gambling , drugs etc . on a show and you're already winning points on in my book . combine all that with acting that <UNK> anything you've ever seen on the small screen , add directing that fits cinema of the vintage type and most of all writing that blows the mind ( and a few brains a long the way ) and you got yourself a show thats gonna be pretty tough to compete with.<br /><br />above all stand two actors , james gandolfini as tony soprano , and <UNK> <UNK> as his wife <UNK> . as for gandolfini , he fits his roll in a way that words cannot express , if you haven't seen him as tony yet see it <UNK> /><br />i can go on and on and on about every character in the show , the psychological brilliance , the gripping scenes etc . but you wouldn't be able to stop me so all i can say is that this is about the only show along with seinfeld , that i am\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "[TEST]\t Loss: 0.4130\t Accuracy: 82.54%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRCFvjwDthiA"
   },
   "source": [
    "# Step 4: Train a Recurrent Neural Network (RNN)\n",
    "We will now build a text clasification model that is based on **recurrences**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-t8tlZviV2x"
   },
   "source": [
    "## Define the RNN Model\n",
    "\n",
    "First, we will define the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nc_HxbP6klI"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, bidirectional, dropout, num_classes, pad_idx):\n",
    "        super(RNN, self).__init__()\n",
    "        self.bidirectional=bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
    "        self.embeddding= nn.Embedding(vocab_size, embed_size, pad_idx)\n",
    "\n",
    "        # Create a recurrent network (use nn.GRU, not nn.LSTM) with batch_first = True\n",
    "        # Make sure you use hidden_size, num_layers, dropout, and bidirectional here.\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, num_layers, dropout=dropout,batch_first=True,bidirectional=bidirectional)\n",
    "        # Create a dropout layer (nn.Dropout) using dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Define a linear layer (nn.Linear) that consists of num_classes units \n",
    "        if self.bidirectional==False:\n",
    "            self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        else:\n",
    "            self.num_layers=self.num_layers*2\n",
    "            self.fc1 = nn.Linear(hidden_size * 2, num_classes)\n",
    "        #   and takes as input the output of the last timestep. In the bidirectional case, you should concatenate\n",
    "        #   the output of the last timestep of the forward direction with the output of the last timestep of the backward direction).\n",
    "        #self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"\n",
    "        texts: LongTensor [batch_size, MAX_LEN]\n",
    "        \n",
    "        Returns output: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
    "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
    "        embedded = self.embeddding(texts)\n",
    "        # Pass the result through your recurrent network\n",
    "        #   See PyTorch documentation for resulting shape for nn.GRU\n",
    "    \n",
    "        # Concatenate the outputs of the last timestep for each direction (see torch.cat(...))\n",
    "        #   This depends on whether or not your model is bidirectional.\n",
    "        #   Resulting shape: [batch_size, num_dirs*hidden_size]\n",
    "        h0=torch.zeros(self.num_layers,embedded.shape[0],self.hidden_size,device=embedded.device)\n",
    "        \n",
    "        packed_output, hidden = self.gru(embedded,h0)\n",
    "        if self.bidirectional==False:\n",
    "          hidden=  hidden[-1,:,:]\n",
    "          \n",
    "        else:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        # Apply dropout\n",
    "        hidden = self.dropout(hidden)\n",
    "        # Pass your output through the linear layer and return its output \n",
    "        #   Resulting shape: [batch_size, num_classes]\n",
    "        if self.bidirectional==False:\n",
    "          dense_outputs=self.fc2(hidden)  \n",
    "        else:\n",
    "            dense_outputs=self.fc1(hidden)\n",
    "        ##### NOTE: Do not apply a sigmoid or softmax to the final output - done in training method!\n",
    "        \n",
    "        return dense_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Duq7X2ClwXga",
    "outputId": "dd825602-1e65-4b61-ca59-56b9d470df5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44546\tYour Num. Params: 44546\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 44676\tYour Num. Params: 44676\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 27202\tYour Num. Params: 27202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 27268\tYour Num. Params: 27268\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82178\tYour Num. Params: 82178\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 82308\tYour Num. Params: 82308\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 39874\tYour Num. Params: 39874\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 39940\tYour Num. Params: 39940\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1620610\tYour Num. Params: 1620610\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1621636\tYour Num. Params: 1621636\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 621698\tYour Num. Params: 621698\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 622212\tYour Num. Params: 622212\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 3986050\tYour Num. Params: 3986050\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 3987076\tYour Num. Params: 3987076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1411202\tYour Num. Params: 1411202\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1411716\tYour Num. Params: 1411716\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 101762\tYour Num. Params: 101762\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 101892\tYour Num. Params: 101892\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 79810\tYour Num. Params: 79810\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 79876\tYour Num. Params: 79876\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 139394\tYour Num. Params: 139394\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 139524\tYour Num. Params: 139524\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 92482\tYour Num. Params: 92482\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 92548\tYour Num. Params: 92548\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1742338\tYour Num. Params: 1742338\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1743364\tYour Num. Params: 1743364\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 706562\tYour Num. Params: 706562\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 707076\tYour Num. Params: 707076\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 4107778\tYour Num. Params: 4107778\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 4108804\tYour Num. Params: 4108804\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 1496066\tYour Num. Params: 1496066\n",
      "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tExpected Num. Params: 1496580\tYour Num. Params: 1496580\n",
      "\n",
      "--- TEST: Output shape of forward(...) ---\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 2])\tYour Output Shape: torch.Size([2, 2])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 150])\tExpected Output Shape: torch.Size([1, 4])\tYour Output Shape: torch.Size([1, 4])\n",
      "\tPASSED\t Init Input: {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}\tForward Input Shape: torch.Size([2, 150])\tExpected Output Shape: torch.Size([2, 4])\tYour Output Shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Test init\n",
    "    inputs = [{'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 256, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0}]\n",
    "    expected_outputs = [44546, 44676, 27202, 27268, 82178, 82308, 39874, 39940, 1620610, 1621636, 621698, 622212, 3986050, 3987076, 1411202, 1411716, 101762, 101892, 79810, 79876, 139394, 139524, 92482, 92548, 1742338, 1743364, 706562, 707076, 4107778, 4108804, 1496066, 1496580]\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"init\", None)\n",
    "    print()\n",
    "\n",
    "    # Test forward\n",
    "    inputs = [{'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 32, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 2, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': True, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'batch_size': 2}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 1}, {'vocab_size': 29730, 'embed_size': 16, 'hidden_size': 64, 'num_layers': 4, 'bidirectional': False, 'dropout': 0, 'num_classes': 4, 'pad_idx': 0, 'batch_size': 2}]\n",
    "    expected_outputs = [torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4]), torch.Size([1, 2]), torch.Size([2, 2]), torch.Size([1, 4]), torch.Size([2, 4])]\n",
    "    sanity_dataset = TextDataset(train_data, 'train', 5, 150)\n",
    "    sanity_loader = torch.utils.data.DataLoader(sanity_dataset, batch_size=50, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    sanityCheckModel(inputs, RNN, expected_outputs, \"forward\", sanity_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baD8lYAytdTV"
   },
   "source": [
    "## Train RNN Model\n",
    "First, we initialize the train and test dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCzNm8LDM5aT"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    THRESHOLD = 5 \n",
    "    MAX_LEN = 200 \n",
    "    BATCH_SIZE = 50 \n",
    "\n",
    "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CA-UairGErap",
    "outputId": "910c14ee-e33e-4164-e27b-c07970d4426b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,300,546 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    rnn_model = RNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
    "                embed_size = 128, \n",
    "                hidden_size = 128, \n",
    "                num_layers = 2,\n",
    "                bidirectional = True,\n",
    "                dropout = 0.5,\n",
    "                num_classes = 2, # Don't change this\n",
    "                pad_idx = train_dataset.word2idx[PAD]) # Don't change this\n",
    "\n",
    "    # Put the model on device\n",
    "    rnn_model = rnn_model.to(DEVICE)\n",
    "\n",
    "    print('The model has {:,d} trainable parameters'.format(count_parameters(rnn_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em6Rs58OlJ3Z"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':    \n",
    "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
    "\n",
    "    # Define your loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "    # Define your optimizer\n",
    "    optimizer = optim.Adam(rnn_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "a210800e51f744a79d35d4aaa847fc9a",
      "605a8460dc0e476ba2b4ac3f9830956e",
      "6a7d3389ffee440188b017ce34db15b1",
      "8cfde2d9b9cf45c5b0faba3d30f89e40",
      "06f737a1f4a04ffa917bedbd9fb9eacc",
      "a1a06326b26348b1a2ed344d0962c215",
      "6792e16200584eb780b2e89cf33ff4d4",
      "a713c3e797f9407eb2b8e183420d1cca",
      "0948b5347c3d443caa125e36a690d992",
      "7dff0f5ba4144973bcae827f476d0c67",
      "01d5c43a4e274af098d63bdb89c78f80"
     ]
    },
    "id": "NR8Wckf0l2G7",
    "outputId": "17aaf70c-d880-41c4-bffb-e27c6bf813c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a210800e51f744a79d35d4aaa847fc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]\t Epoch:  1\t Loss: 0.6693\t Train Accuracy: 57.93%\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.5614\t Train Accuracy: 71.08%\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.4039\t Train Accuracy: 82.07%\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.3160\t Train Accuracy: 86.72%\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.2478\t Train Accuracy: 90.25%\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.1861\t Train Accuracy: 92.69%\n",
      "Model Trained!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    N_EPOCHS = 6 # \n",
    "    \n",
    "    # train model for N_EPOCHS epochs\n",
    "    train_model(rnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-SRIFfooYk6"
   },
   "source": [
    "## Evaluate RNN Model\n",
    "\n",
    "Now we can evaluate the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607,
     "referenced_widgets": [
      "3088481ac3c44f0eb3eb92f3c6374ffb",
      "05a6f6038ffe48fcaf112e2a9749a803",
      "488d3f6f665c43ddaafd8eedcea80040",
      "7bbf554d828c4ed89f623776a1481551",
      "675813db9d334187b704650da1085df6",
      "07a1e0c59549400195891f8135a063ee",
      "f5f8541d4569423fb575d43762293244",
      "544d749cbd7e495594f31b1818a310f2",
      "e74bbef409524f38891add0e36f7c972",
      "7977747d8448426f9b7186a70c16810c",
      "7b722efe9982442a91329671a5a15d14"
     ]
    },
    "id": "HYon4AbHl5_M",
    "outputId": "12661df2-7e0d-412a-b2e2-615834fc5802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance on the test dataset...\n",
      "\n",
      "SOME PREDICTIONS FROM THE MODEL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3088481ac3c44f0eb3eb92f3c6374ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: when thinking of the revelation that the main character in \" bubble \" comes to at films end , i am reminded of last years \" <UNK> \" with christian <UNK> . the only difference between the two films is the literal physical weight of the characters.<br /><br />an understated , yet entirely realistic portrayal of small town life . the title is cause for contemplation . perhaps , we , the audience are the ones in the \" bubble \" as we are given no <UNK> in the films slim 90 minute running time . audience reactions were often smug and judgmental , clearly indicating how detached people can be from seeing any thread of humanity in characters so foreign to themselves . these characters are the ones people refer to as those that put george w . back in office for a second <UNK> /><br />it's <UNK> to consider how reality television has spoiled our sense of reality when watching an audience jump to their feet for the exit as soon as the credits role . this film has it's merits , and is deserving of consideration for the things it doesn't say outright .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: it has a great name , but thats it and you wont get more than that for your money , in fact the first <UNK> of the movie you might find it some kind of funny but after that the story goes from one side to another with no particular reason and you just cant understand whats happening until the action its gone.<br /><br />and yet the producers ( roberto angel <UNK> ) calls him an actor , but i don't think the way he does could be called nothing but <UNK> . the little kid who plays as his son has totally no sense of acting and i believe it was just a favor he did or something because he had no clue of what he was doing.<br /><br />for some reason while doing the casting they thought that by casting comedians they could made it , but they <UNK> ! and sometimes the tasteless cheap humor its so bad , i don't buy it.<br /><br />but hopefully this is as bad as it gets . to make people accept those dvd's to the good taste public they will have to offer some food with it , that might\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: first of all , what is good in the movie  ? some pretty actress  ? the exotic background  ? the fact that the actors don't laugh while acting ( i would have if i had been in their situation )  ? i don't know . the storyline is simple  : a catholic priest who does abstract painting tries to find out who ( another abstract painter ) killed his little brother , a male prostitute ( raped by another priest when he was <UNK> . i'm afraid there is nothing here to learn or to let think a little about serial killers , art or religion . dennis hopper is not very good here . this is the worst episode of the worst season of \" <UNK> \" ( the <UNK> ) with replacement actors and unbelievable coincidences ( the uncle is the policeman who , the girl who lives at another victim's house could have a baby with the priest , etc. , etc) .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: this apocalyptic zombie film tries to be vicious and shocking ; but feeding the masses comes off lame as some of the <UNK> zombies stalking the streets . in rhode island , a zombie epidemic known as the <UNK> virus is being played down by the government manipulated newspapers and television stations . a couple of brave , but dumb , souls at channel 5 tv news feels its audience is being given false hope and no idea of the real danger at hand . an eager <UNK> <UNK> her <UNK> <UNK> , with the aid of a military <UNK> <UNK> , risk life and limb to present a ' live ' broadcast to show the doom at hand . do yourself a favor and don't watch . this thing is obviously very low budget and comes across with the feel of a high school play gone bad . acting is atrocious and the <UNK> zombies are almost comical . also appearing are : michael <UNK> , william <UNK> and brenda hogan . feeding the masses should be left to <UNK> .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: oh my god ! this movie insults the intelligence of everybody . i mean really , who thinks three kids can fight 30 to 40 ninjas and win . not to mention the brainless humor thrown in . this film is <UNK> . the movie is an omen , the only thing it's good for is a time killer or unintentional laughs .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: no spoilers here but i have been a fan since waking the dead started but the last series , of which only 3 have been on so far is awful . the stories bear no resemblance to the original idea of the series . i found these 3 in the last series jaw <UNK> ludicrous . as a bbc licence <UNK> , after the show i rang bbc complaints to pass on my disappointment . i'm amazed that actors of the calibre of trevor eve and sue <UNK> didn't object to the story lines . these actors have been with these characters for 8 seasons , surly they can see it's lost all direction . it's a good job it is the last series or the next series may start with the team investigating the death of father <UNK> /><br />paul bentley , west yorkshire , england .\n",
      "Prediction: 0 \tCorrect Output: 0 \n",
      "\n",
      "Input: the reason why people say that this movie scared them is because it <UNK> ! that means the movie purpose was felt by a few who did see it . when i first saw this movie it scared me and made me think about life and religion . this is not a blood and gore scary type movie , but the kind that you would think that it may be possible for things to happen the way the movie was written . of course non believers will say its only a sci-fi movie . truth is , this movie is a must have for your thriller collection , even if it does have a religious view . if you are a fan of classic thrillers ( <UNK> ) this is one of them and its a must have . i never saw the sequel ( distant <UNK> , but i believe it picks up where this movie ends .\n",
      "Prediction: 1 \tCorrect Output: 1 \n",
      "\n",
      "Input: there are people claiming this is another \" bad language \" ultra violence mexican movie . they are right , but more than that this film is a call to create awareness of what we have become . the awful truth hurts , or bores when you already have accepted the paradigm of living the third world as the only possible goal . one of the most important things of \" <UNK> y van <UNK> \" is the open invitation to profound <UNK> over our current identity . is that what we all are ? is that all that we want to be ? i am abroad and i realized how spoiled is the mexican society when the <UNK> incident came to light . i still cannot understand viewers witnessing a mass <UNK> murder . i nearly <UNK> when i saw some of the images . it was not <UNK> or <UNK> , just a tiny village near mexico city when rampage was carried out with the indulgence of media and government . the recreation of a similar situation in this film shocked me deeply . the other stories were good portraying other situations of corruption , <UNK> , betrayal\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "Input: this movie is obviously low-budget & filmed in british <UNK> . the obstacles that had to be overcome to make this movie <UNK> in california & late <UNK> well <UNK> believe this is the best & most accurate version of the zodiac killings that plagued the town of <UNK> & the bay area from <UNK> ? ( he was never <UNK> james <UNK> . dave <UNK> ) & george <UNK> the time believed to be arthur leigh allen , since cleared by dna & <UNK> a game of cat & mouse <UNK> crime scenes together , each one trying to trigger the other into an emotional <UNK> dying from some type of terminal disease & knowing <UNK> did <UNK> totally obsessed to the point of losing his family & becoming a full blown alcoholic along the <UNK> totally oblivious & self <UNK> all serial killers ) to the carnage left in his <UNK> only disappointment was <UNK> the top \" ending otherwise pretty <UNK> you tire of the typical hollywood fluff or have an interest in the zodiac <UNK> it out .\n",
      "Prediction: 0 \tCorrect Output: 1 \n",
      "\n",
      "[TEST]\t Loss: 0.5195\t Accuracy: 80.60%\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':    \n",
    "    evaluate(rnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003de8d84d4a4eb0a9d697999b4f2be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c795e3ecaeb4c9c80bf5489e206bc24",
      "placeholder": "â",
      "style": "IPY_MODEL_f616197f58614627a5ce157ccce3e350",
      "value": " 10/10 [03:55&lt;00:00, 23.26s/it]"
     }
    },
    "01d5c43a4e274af098d63bdb89c78f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05a6f6038ffe48fcaf112e2a9749a803": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07a1e0c59549400195891f8135a063ee",
      "placeholder": "â",
      "style": "IPY_MODEL_f5f8541d4569423fb575d43762293244",
      "value": "100%"
     }
    },
    "06f737a1f4a04ffa917bedbd9fb9eacc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07a1e0c59549400195891f8135a063ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0948b5347c3d443caa125e36a690d992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3088481ac3c44f0eb3eb92f3c6374ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05a6f6038ffe48fcaf112e2a9749a803",
       "IPY_MODEL_488d3f6f665c43ddaafd8eedcea80040",
       "IPY_MODEL_7bbf554d828c4ed89f623776a1481551"
      ],
      "layout": "IPY_MODEL_675813db9d334187b704650da1085df6"
     }
    },
    "448ea785839146f6b39bfc2a853dbee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488d3f6f665c43ddaafd8eedcea80040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_544d749cbd7e495594f31b1818a310f2",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e74bbef409524f38891add0e36f7c972",
      "value": 5000
     }
    },
    "4f99333efd0e4807a8993d7994656ec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "544d749cbd7e495594f31b1818a310f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d71e2aaa344b889780872f4f908589": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66f85b00d7c04448b8819b49f7af35f1",
      "placeholder": "â",
      "style": "IPY_MODEL_dba97039d7184983a5a84560d34d2951",
      "value": "100%"
     }
    },
    "59edd186b3d6454682a61124014807fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a05d4e03e6d473ba0c258c0183b3e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c795e3ecaeb4c9c80bf5489e206bc24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e826625eba442f2bdc97823a848b148": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_448ea785839146f6b39bfc2a853dbee4",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95364d7916c343668e22d462499e0428",
      "value": 5000
     }
    },
    "605a8460dc0e476ba2b4ac3f9830956e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1a06326b26348b1a2ed344d0962c215",
      "placeholder": "â",
      "style": "IPY_MODEL_6792e16200584eb780b2e89cf33ff4d4",
      "value": "100%"
     }
    },
    "6276074cc05a4d88b4d94cfa19622aa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66f85b00d7c04448b8819b49f7af35f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "675813db9d334187b704650da1085df6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6792e16200584eb780b2e89cf33ff4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a7d3389ffee440188b017ce34db15b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a713c3e797f9407eb2b8e183420d1cca",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0948b5347c3d443caa125e36a690d992",
      "value": 6
     }
    },
    "7977747d8448426f9b7186a70c16810c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b722efe9982442a91329671a5a15d14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bbf554d828c4ed89f623776a1481551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7977747d8448426f9b7186a70c16810c",
      "placeholder": "â",
      "style": "IPY_MODEL_7b722efe9982442a91329671a5a15d14",
      "value": " 5000/5000 [00:17&lt;00:00, 281.98it/s]"
     }
    },
    "7dff0f5ba4144973bcae827f476d0c67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8110a9a5dc4c4dd483841f93911244f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8446114f8cea415ebd55567ec17177cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89a8777537bc48359942a911ac80c2a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f99333efd0e4807a8993d7994656ec7",
      "placeholder": "â",
      "style": "IPY_MODEL_eefa20ac58e84d6d9d37f750bf2ee685",
      "value": "100%"
     }
    },
    "8cfde2d9b9cf45c5b0faba3d30f89e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dff0f5ba4144973bcae827f476d0c67",
      "placeholder": "â",
      "style": "IPY_MODEL_01d5c43a4e274af098d63bdb89c78f80",
      "value": " 6/6 [00:49&lt;00:00,  8.19s/it]"
     }
    },
    "95364d7916c343668e22d462499e0428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1a06326b26348b1a2ed344d0962c215": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a20f07cffd3e4ff7b183de9c5371a403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59d71e2aaa344b889780872f4f908589",
       "IPY_MODEL_5e826625eba442f2bdc97823a848b148",
       "IPY_MODEL_fb2540bd84434509b961e3654478c790"
      ],
      "layout": "IPY_MODEL_5a05d4e03e6d473ba0c258c0183b3e9a"
     }
    },
    "a210800e51f744a79d35d4aaa847fc9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_605a8460dc0e476ba2b4ac3f9830956e",
       "IPY_MODEL_6a7d3389ffee440188b017ce34db15b1",
       "IPY_MODEL_8cfde2d9b9cf45c5b0faba3d30f89e40"
      ],
      "layout": "IPY_MODEL_06f737a1f4a04ffa917bedbd9fb9eacc"
     }
    },
    "a5488b705e064cda8afd45255ecfbcbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a713c3e797f9407eb2b8e183420d1cca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac22a2eba6b741d5acd0d04bd897050e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59edd186b3d6454682a61124014807fa",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6276074cc05a4d88b4d94cfa19622aa5",
      "value": 10
     }
    },
    "b0760a205da8490fa94b0f5597c478e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89a8777537bc48359942a911ac80c2a6",
       "IPY_MODEL_ac22a2eba6b741d5acd0d04bd897050e",
       "IPY_MODEL_003de8d84d4a4eb0a9d697999b4f2be0"
      ],
      "layout": "IPY_MODEL_8446114f8cea415ebd55567ec17177cd"
     }
    },
    "dba97039d7184983a5a84560d34d2951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e74bbef409524f38891add0e36f7c972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eefa20ac58e84d6d9d37f750bf2ee685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5f8541d4569423fb575d43762293244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f616197f58614627a5ce157ccce3e350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb2540bd84434509b961e3654478c790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8110a9a5dc4c4dd483841f93911244f6",
      "placeholder": "â",
      "style": "IPY_MODEL_a5488b705e064cda8afd45255ecfbcbe",
      "value": " 5000/5000 [00:15&lt;00:00, 330.72it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
